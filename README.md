# ğŸ¤– InsightStock AI Service

AI Service for InsightStock - LLM/SLM integration with Ollama (Python)

## ğŸ“‹ ê°œìš”

ì´ ì„œë¹„ìŠ¤ëŠ” InsightStockì˜ AI ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ë³„ë„ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥
- **LLM/SLM í†µí•©**: Ollama ê¸°ë°˜ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ì‚¬ìš©
- **ë²¡í„° ê²€ìƒ‰**: Pineconeì„ í†µí•œ RAG êµ¬í˜„
- **ëª¨ë¸ ë¼ìš°íŒ…**: ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¥¸ ìë™ ëª¨ë¸ ì„ íƒ
- **Jupyter Notebook**: AI íŒŒì‹± ë° ë²¡í„° DB ì‘ì—…ìš©

## ğŸ—ï¸ êµ¬ì¡°

```
insightstock-ai-service/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ services/          # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”‚   â”œâ”€â”€ llm_service.py
â”‚   â”‚   â”œâ”€â”€ slm_service.py
â”‚   â”‚   â”œâ”€â”€ model_router.py
â”‚   â”‚   â””â”€â”€ vector_search_service.py
â”‚   â”œâ”€â”€ models/             # ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸
â”‚   â”‚   â”œâ”€â”€ ollama_client.py
â”‚   â”‚   â””â”€â”€ model_config.py
â”‚   â”œâ”€â”€ controllers/       # API ì»¨íŠ¸ë¡¤ëŸ¬
â”‚   â”‚   â”œâ”€â”€ chat_controller.py
â”‚   â”‚   â””â”€â”€ search_controller.py
â”‚   â”œâ”€â”€ utils/             # ìœ í‹¸ë¦¬í‹°
â”‚   â”‚   â””â”€â”€ query_classifier.py
â”‚   â””â”€â”€ main.py            # FastAPI ì„œë²„
â”‚
â”œâ”€â”€ notebooks/             # Jupyter Notebooks
â”‚   â”œâ”€â”€ embeddings.ipynb          # ì„ë² ë”© ìƒì„±
â”‚   â”œâ”€â”€ vector_search.ipynb       # ë²¡í„° ê²€ìƒ‰ ì‹¤í—˜
â”‚   â”œâ”€â”€ indexing.ipynb            # ì¸ë±ì‹± ì‘ì—…
â”‚   â”œâ”€â”€ parse_news.ipynb          # ë‰´ìŠ¤ ë°ì´í„° íŒŒì‹±
â”‚   â”œâ”€â”€ parse_stocks.ipynb        # ì£¼ì‹ ë°ì´í„° íŒŒì‹±
â”‚   â””â”€â”€ parse_learnings.ipynb     # í•™ìŠµ ì½˜í…ì¸  íŒŒì‹±
â”‚
â”œâ”€â”€ tests/                 # í…ŒìŠ¤íŠ¸
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒ í™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ ìˆ˜ì •
```

### 2. Ollama ì„¤ì¹˜ ë° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```bash
# Ollama ì„¤ì¹˜ (https://ollama.com)
# macOS
brew install ollama

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull phi3.5
ollama pull qwen2.5:7b
ollama pull llama3.1:70b
```

### 3. ì„œë²„ ì‹¤í–‰

```bash
# ê°œë°œ ëª¨ë“œ (ê¶Œì¥)
cd src
python main.py

# ë˜ëŠ” uvicorn ì§ì ‘ ì‚¬ìš©
uvicorn src.main:app --reload --port 3002

# ë˜ëŠ” Makefile ì‚¬ìš©
make run
```

ì„œë²„ê°€ ì‹¤í–‰ë˜ë©´:
- API ì„œë²„: http://localhost:3002
- API ë¬¸ì„œ: http://localhost:3002/docs (Swagger UI)
- Health Check: http://localhost:3002/health

### 4. ì±— ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

```bash
# í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python test_chat.py

# ë˜ëŠ” curlë¡œ ì§ì ‘ í…ŒìŠ¤íŠ¸
curl -X POST http://localhost:3002/api/chat \
  -H "Content-Type: application/json" \
  -d '{"query": "ì•ˆë…•í•˜ì„¸ìš”"}'
```

ìì„¸í•œ í…ŒìŠ¤íŠ¸ ë°©ë²•ì€ [QUICK_START.md](./QUICK_START.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

### 4. Jupyter Notebook ì‹¤í–‰

```bash
# Jupyter Lab ì‹¤í–‰
jupyter lab

# ë˜ëŠ” Jupyter Notebook
jupyter notebook
```

## ğŸ“š ì£¼ìš” ëª¨ë“ˆ

### Jupyter Notebooks

#### `notebooks/embeddings.ipynb`
- OpenAI Embeddingsë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
- ë²¡í„° ë³€í™˜ ì‹¤í—˜ ë° í…ŒìŠ¤íŠ¸

#### `notebooks/vector_search.ipynb`
- Pinecone ë²¡í„° ê²€ìƒ‰ ì‹¤í—˜
- ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸

#### `notebooks/indexing.ipynb`
- ë°ì´í„° ì¸ë±ì‹± ì‘ì—…
- ë°°ì¹˜ ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸

#### `notebooks/parse_*.ipynb`
- ë‰´ìŠ¤, ì£¼ì‹, í•™ìŠµ ì½˜í…ì¸  íŒŒì‹±
- ë°ì´í„° ì „ì²˜ë¦¬ ë° ì •ì œ

### Python ëª¨ë“ˆ

#### `src/services/llm_service.py`
- Ollama ê¸°ë°˜ LLM í†µí•©
- ìŠ¤íŠ¸ë¦¬ë° ì§€ì›

#### `src/services/vector_search_service.py`
- Pinecone ë²¡í„° ê²€ìƒ‰
- Jupyterì—ì„œ ì‹¤í—˜í•œ ë¡œì§ì„ ëª¨ë“ˆí™”

## ğŸ”§ í™˜ê²½ ë³€ìˆ˜

### í•„ìˆ˜ ì„¤ì •

```bash
# OpenAI (ì„ë² ë”© ìƒì„± í•„ìˆ˜)
OPENAI_API_KEY=your_key_here

# Pinecone (ë²¡í„° DB - ë¬´ë£Œ í‹°ì–´ ì‚¬ìš© ê°€ëŠ¥)
PINECONE_API_KEY=your_key_here
PINECONE_INDEX_NAME=insightstock

# Redis (ìºì‹± - ì„ íƒì‚¬í•­, ê¶Œì¥)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Backend API (ë™ê¸°í™”ìš©)
BACKEND_API_URL=http://localhost:3001
```

### ì„ íƒ ì„¤ì •

```bash
# Ollama (ë¡œì»¬ LLM/SLM - ë¬´ë£Œ)
OLLAMA_HOST=http://localhost:11434

# Anthropic Claude (ì„ íƒì‚¬í•­)
ANTHROPIC_API_KEY=your_key_here

# Google Gemini (ì„ íƒì‚¬í•­)
GEMINI_API_KEY=your_key_here

# Server
PORT=3002
HOST=0.0.0.0
LOG_LEVEL=INFO

# ë¹„ìš© ìµœì í™”
EMBEDDING_MODEL=text-embedding-3-small
```

### ìƒì„¸ ê°€ì´ë“œ

ìì„¸í•œ ì„¤ì • ë°©ë²•ì€ [ENV_SETUP_GUIDE.md](./ENV_SETUP_GUIDE.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ³ Docker

```bash
# ë¹Œë“œ
docker build -t insightstock-ai-service .

# ì‹¤í–‰
docker-compose up
```

## ğŸ“ ê°œë°œ ì›Œí¬í”Œë¡œìš°

1. **Jupyterì—ì„œ ì‹¤í—˜**: `notebooks/`ì—ì„œ AI íŒŒì‹±, ë²¡í„° ê²€ìƒ‰ ë“± ì‹¤í—˜
2. **Python ëª¨ë“ˆí™”**: ì‹¤í—˜ ê²°ê³¼ë¥¼ `src/services/`ì— ëª¨ë“ˆë¡œ êµ¬í˜„
3. **API í†µí•©**: FastAPI ì»¨íŠ¸ë¡¤ëŸ¬ì—ì„œ ì‚¬ìš©
4. **í…ŒìŠ¤íŠ¸**: `tests/`ì—ì„œ ë‹¨ìœ„/í†µí•© í…ŒìŠ¤íŠ¸

## ğŸ”— ë©”ì¸ ë°±ì—”ë“œ ì—°ë™

ë©”ì¸ ë°±ì—”ë“œ(insightstock-backend)ì—ì„œ ì´ ì„œë¹„ìŠ¤ë¥¼ í˜¸ì¶œ:

```typescript
// ChatService.ts
const response = await fetch(`${AI_SERVICE_URL}/chat/stream`, {
  method: 'POST',
  body: JSON.stringify({ query, messages }),
});
```

## ğŸ“Š ëª¨ë¸ ì„ íƒ ì „ëµ

- **ê°„ë‹¨í•œ ì§ˆë¬¸**: Phi-3.5 (SLM, ë¹ ë¦„)
- **ì¼ë°˜ ëŒ€í™”**: Qwen2.5 7B (LLM, ê· í˜•)
- **ë³µì¡í•œ ë¶„ì„**: Llama 3.1 70B (LLM, ì •í™•)

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ISC
